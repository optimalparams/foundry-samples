{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa2c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import requests\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb02698",
   "metadata": {},
   "source": [
    "# Mistral Document AI Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b848b6b4",
   "metadata": {},
   "source": [
    "Mistral Document AI offers enterprise-level document processing, combining cutting-edge OCR technology with advanced structured data extraction. This notebook showcases a few examples of basic OCR extraction for text and images.\n",
    "\n",
    "We will be using the `mistral-document-ai-2505` model with a few documents and images to show the capabilities of the model.\n",
    "\n",
    "> **Note**: The Document AI endpoint on Azure Foundry cannot process sources from external URLSs, instead we show you how to encode documents and images and call the API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36602e65",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_MISTRAL_DOCUMENT_AI_ENDPOINT = \"\"\n",
    "AZURE_MISTRAL_DOCUMENT_AI_KEY = \"\"\n",
    "REQUEST_HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {AZURE_MISTRAL_DOCUMENT_AI_KEY}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad960898",
   "metadata": {},
   "source": [
    "Get PDFs for samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1051391",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/mistralai/cookbook/refs/heads/main/mistral/ocr/mistral7b.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08403fb3",
   "metadata": {},
   "source": [
    "## 1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8fc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path: str) -> str:\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {image_path} was not found.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def replace_images_in_markdown(markdown_str: str, images_dict: dict) -> str:\n",
    "    for img_name, base64_str in images_dict.items():\n",
    "        markdown_str = markdown_str.replace(\n",
    "            f\"![{img_name}]({img_name})\", f\"![{img_name}]({base64_str})\"\n",
    "        )\n",
    "    return markdown_str\n",
    "\n",
    "\n",
    "def simple_combined_markdown(responsePage: dict) -> str:\n",
    "    markdowns: list[str] = []\n",
    "    image_data = {}\n",
    "    for img in responsePage[\"images\"]:\n",
    "        image_data[img[\"id\"]] = img[\"image_base64\"]\n",
    "    markdowns.append(replace_images_in_markdown(responsePage[\"markdown\"], image_data))\n",
    "\n",
    "    return \"\\n\\n\".join(markdowns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4dd9de",
   "metadata": {},
   "source": [
    "## 2. Basic OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f669f26",
   "metadata": {},
   "source": [
    "In this example, we show how to extract text from a PDF document using Mistral Document AI. In addition to PDFs we support .docx, and .pptx file types, as well as many common image formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87736dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedDocument = encode_image(\"mistral7b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f46097",
   "metadata": {},
   "source": [
    "Next we construct the JSON for the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431c0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentPayload = {\n",
    "    \"model\": \"mistral-document-ai-2505\",\n",
    "    \"document\": {\n",
    "        \"type\": \"document_url\",\n",
    "        \"document_url\": f\"data:application/pdf;base64,{encodedDocument}\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ecd511",
   "metadata": {},
   "source": [
    "Construct the request and parse the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9cb39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentResponse = requests.post(\n",
    "    url=AZURE_MISTRAL_DOCUMENT_AI_ENDPOINT,\n",
    "    json=documentPayload,\n",
    "    headers=REQUEST_HEADERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e75c896",
   "metadata": {},
   "source": [
    "You will notice that for every page, the API returns text data in markdown format, along with information about detected images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43360e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(documentResponse.json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documentResponse.json()[\"pages\"][0][\"markdown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(documentResponse.json()[\"pages\"][0][\"markdown\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8303b986",
   "metadata": {},
   "source": [
    "If you are interested in just the text, this works fine. If you need the images along with the text we will need to return the images in the response, and then combine with the markdown text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e65b6f",
   "metadata": {},
   "source": [
    "## 3. OCR with Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23679396",
   "metadata": {},
   "source": [
    "In the previous section we saw how easy it is to get the text from a document. If you want to get the images along with the text, all you have to do is set the `include_image_base64` parameter in our request and handle the returned base64-encoded image in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c80193",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentPayloadandImages = {\n",
    "    \"model\": \"mistral-document-ai-2505\",\n",
    "    \"document\": {\n",
    "        \"type\": \"document_url\",\n",
    "        \"document_url\": f\"data:application/pdf;base64,{encodedDocument}\",\n",
    "    },\n",
    "    \"include_image_base64\": \"true\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "docWithImagesResponse = requests.post(\n",
    "    url=AZURE_MISTRAL_DOCUMENT_AI_ENDPOINT,\n",
    "    json=documentPayloadandImages,\n",
    "    headers=REQUEST_HEADERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0126c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(simple_combined_markdown(docWithImagesResponse.json()[\"pages\"][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341c6e5",
   "metadata": {},
   "source": [
    "And viola! We have the combined text and images. This is useful for converting documents into markdown format, and being able to programmatically extract the text and images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0accf6d",
   "metadata": {},
   "source": [
    "# 4. Tabular Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3184239a",
   "metadata": {},
   "source": [
    "Next we look at a document with tabular data, for this example we are using Microsoft's 8-K filing located here: https://www.microsoft.com/en-us/investor/sec-filings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0906e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms8kDocument = encode_image(\"0000950170-25-100226.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250ed561",
   "metadata": {},
   "outputs": [],
   "source": [
    "msRequestPayload = {\n",
    "    \"model\": \"mistral-document-ai-2505\",\n",
    "    \"document\": {\n",
    "        \"type\": \"document_url\",\n",
    "        \"document_url\": f\"data:application/pdf;base64,{ms8kDocument}\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d93c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms8kResponse = requests.post(\n",
    "    url=AZURE_MISTRAL_DOCUMENT_AI_ENDPOINT,\n",
    "    json=msRequestPayload,\n",
    "    headers=REQUEST_HEADERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9247e",
   "metadata": {},
   "source": [
    "Selecting a page with tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a167260",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(simple_combined_markdown(ms8kResponse.json()[\"pages\"][5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c134a",
   "metadata": {},
   "source": [
    "As observed, the extracted text in the table is accurate and true to the original tabular representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188408f8",
   "metadata": {},
   "source": [
    "# 4. Wrap-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9166e954",
   "metadata": {},
   "source": [
    "Documents and images are a wealth of information, but that information is only useful if it can be extracted accurately. Mistral Document AI on Azure is a powerful tool that can help you extract text and images from documents accurately, with ease. We hope you found this notebook helpful and we look forward to seeing what you build with it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
